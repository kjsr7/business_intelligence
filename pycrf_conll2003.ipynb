{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pycrf-conll2003.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/kjsr7/business_intelligence/blob/master/pycrf_conll2003.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "QxsJcvAjPeBY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition using sklearn-crfsuite"
      ]
    },
    {
      "metadata": {
        "id": "nOfj0JuVPx1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c1c44e5-e39e-4365-ff16-8beb0cbd74f0"
      },
      "cell_type": "code",
      "source": [
        "!pip install python-crfsuite"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-crfsuite in /usr/local/lib/python3.6/dist-packages (0.9.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DCgSEfO8QI24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a736a09a-c085-4f58-9b5e-7340ffe60330"
      },
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zhST-c1kPeBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a9d8571-dcf4-4097-bf11-9adf2958320e"
      },
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "import nltk\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import sklearn\n",
        "import pycrfsuite\n",
        "\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.19.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gSJWck4XRHxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7a29eead-842e-4876-df8d-b0f1f2a5bbbc"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('conll2002')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2002.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "c5HXsEEtPeBn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's use CoNLL 2003 data to build a NER systemÂ¶\n",
        "CoNLL2002 corpus processing functions are available in NLTK. We use these functions to preprocess coNLL2003 dataset"
      ]
    },
    {
      "metadata": {
        "id": "hqdxtFuZPeBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15adfbdb-bef2-401c-ceaf-caa07068898d"
      },
      "cell_type": "code",
      "source": [
        "nltk.corpus.conll2002.fileids()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "gW7SRl8nVV5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp eng.* /root/nltk_data/corpora/conll2002/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I_ZO6BdYPeBw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Training data\n",
        "CoNLL 2003 dataset contains a list of english sentences, with Named Entities annotated. It uses IOB2 encoding. CoNLL 2003 data also provide POS tags."
      ]
    },
    {
      "metadata": {
        "id": "R2caFR_cPeBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9aba643b-445c-4fb5-e21c-8401b620e450"
      },
      "cell_type": "code",
      "source": [
        "train_sents = list(nltk.corpus.conll2002.iob_sents('eng.train'))\n",
        "test_sents = list(nltk.corpus.conll2002.iob_sents('eng.testb'))\n",
        "len(train_sents)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "0fD4SEtpPeB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9229ba8c-bc1e-4edb-a7d0-11008fce9906"
      },
      "cell_type": "code",
      "source": [
        "train_sents[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('EU', 'NNP', 'I-ORG'),\n",
              " ('rejects', 'VBZ', 'O'),\n",
              " ('German', 'JJ', 'I-MISC'),\n",
              " ('call', 'NN', 'O'),\n",
              " ('to', 'TO', 'O'),\n",
              " ('boycott', 'VB', 'O'),\n",
              " ('British', 'JJ', 'I-MISC'),\n",
              " ('lamb', 'NN', 'O'),\n",
              " ('.', '.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "cJITTXw2PeB_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction\n",
        "Next, define some features. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used. This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it."
      ]
    },
    {
      "metadata": {
        "id": "j9X6nkvfPeCB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(),\n",
        "        'word.istitle=%s' % word.istitle(),\n",
        "        'word.isdigit=%s' % word.isdigit(),\n",
        "        'postag=' + postag,\n",
        "        'postag[:2]=' + postag[:2],\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "            '-1:postag=' + postag1,\n",
        "            '-1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "            '+1:postag=' + postag1,\n",
        "            '+1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLQjs_RmPeCG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SvLd50SCPeCL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "umhMEti0PeCT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PjA1ZGWAPeCZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is what word2features extracts:"
      ]
    },
    {
      "metadata": {
        "id": "olvR3S55LbNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "outputId": "704b3ec8-0460-4f4b-da5e-d1c13050c0b1"
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemTotal:       13335204 kB\n",
            "MemFree:         9841408 kB\n",
            "MemAvailable:   12325468 kB\n",
            "Buffers:           46840 kB\n",
            "Cached:          2589924 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           953996 kB\n",
            "Inactive:        2330652 kB\n",
            "Active(anon):     606084 kB\n",
            "Inactive(anon):      308 kB\n",
            "Active(file):     347912 kB\n",
            "Inactive(file):  2330344 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               260 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        647892 kB\n",
            "Mapped:           166020 kB\n",
            "Shmem:               796 kB\n",
            "Slab:             121968 kB\n",
            "SReclaimable:      95100 kB\n",
            "SUnreclaim:        26868 kB\n",
            "KernelStack:        3376 kB\n",
            "PageTables:         5204 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6667600 kB\n",
            "Committed_AS:    2053480 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:           0 kB\n",
            "VmallocChunk:          0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "DirectMap4k:       53236 kB\n",
            "DirectMap2M:     5189632 kB\n",
            "DirectMap1G:    10485760 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2xj6Vbo6PeCa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "dd5d67f7-5660-493d-ac8b-a347c55f313f"
      },
      "cell_type": "code",
      "source": [
        "sent2features(train_sents[0])[1]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bias',\n",
              " 'word.lower=rejects',\n",
              " 'word[-3:]=cts',\n",
              " 'word[-2:]=ts',\n",
              " 'word.isupper=False',\n",
              " 'word.istitle=False',\n",
              " 'word.isdigit=False',\n",
              " 'postag=VBZ',\n",
              " 'postag[:2]=VB',\n",
              " '-1:word.lower=eu',\n",
              " '-1:word.istitle=False',\n",
              " '-1:word.isupper=True',\n",
              " '-1:postag=NNP',\n",
              " '-1:postag[:2]=NN',\n",
              " '+1:word.lower=german',\n",
              " '+1:word.istitle=True',\n",
              " '+1:word.isupper=False',\n",
              " '+1:postag=JJ',\n",
              " '+1:postag[:2]=JJ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "dI3tHm4iPeCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract the features from the data:"
      ]
    },
    {
      "metadata": {
        "id": "pOYRgoODPeCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ee847184-4dff-4869-e6dc-59f0a46d7c9a"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.66 s, sys: 327 ms, total: 1.99 s\n",
            "Wall time: 1.99 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EpbVp3IlPeCu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_eHthwwRPeCz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "To train the model, we create pycrfsuite.Trainer, load the training data and call 'train' method. First, create pycrfsuite.Trainer and load the training data to CRFsuite:"
      ]
    },
    {
      "metadata": {
        "id": "b5gAreEEPeC1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer = pycrfsuite.Trainer(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-kO7K87KPeC6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YwzMv4bpPeDA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set training parameters. We will use L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization."
      ]
    },
    {
      "metadata": {
        "id": "r1TD60OSPeDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 50,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ysSq9pRWPeDI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Possible parameters for the default training algorithm:"
      ]
    },
    {
      "metadata": {
        "id": "vSlhjbJdPeDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "779dca6f-3e84-4c65-d27a-bf62505ce2bc"
      },
      "cell_type": "code",
      "source": [
        "trainer.params()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['feature.minfreq',\n",
              " 'feature.possible_states',\n",
              " 'feature.possible_transitions',\n",
              " 'c1',\n",
              " 'c2',\n",
              " 'max_iterations',\n",
              " 'num_memories',\n",
              " 'epsilon',\n",
              " 'period',\n",
              " 'delta',\n",
              " 'linesearch',\n",
              " 'max_linesearch']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "gL_g57IgPeDT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model:"
      ]
    },
    {
      "metadata": {
        "id": "x2vcHPxpPeDU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer.train('conll2002-esp.crfsuite')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WxQqYSUePeDZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also get information about the final state of the model by looking at the trainer's logparser. If we had tagged our input data using the optional group argument in add, and had used the optional holdout argument during train, there would be information about the trainer's performance on the holdout set as well."
      ]
    },
    {
      "metadata": {
        "id": "Up-jieklPeDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "299f1170-a686-497e-e5ba-93a522b54e47"
      },
      "cell_type": "code",
      "source": [
        "trainer.logparser.last_iteration"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'active_features': 8902,\n",
              " 'error_norm': 769.368767,\n",
              " 'feature_norm': 108.543567,\n",
              " 'linesearch_step': 1.0,\n",
              " 'linesearch_trials': 1,\n",
              " 'loss': 14546.233784,\n",
              " 'num': 50,\n",
              " 'scores': {},\n",
              " 'time': 0.254}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "CW7_PgVPPeDj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also get this information for every step using trainer.logparser.iterations"
      ]
    },
    {
      "metadata": {
        "id": "Mu7tyRVpPeDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "57c502e5-d5be-452b-f41f-54feefca13eb"
      },
      "cell_type": "code",
      "source": [
        "print(len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50 {'num': 50, 'scores': {}, 'loss': 14546.233784, 'feature_norm': 108.543567, 'error_norm': 769.368767, 'active_features': 8902, 'linesearch_trials': 1, 'linesearch_step': 1.0, 'time': 0.254}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B407Dg0WPeDp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make predictions\n",
        "To use the trained model, create pycrfsuite.Tagger, open the model and use \"tag\" method:"
      ]
    },
    {
      "metadata": {
        "id": "9gLD66sIPeDr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('conll2002-esp.crfsuite')\n",
        "\n",
        "example_sent = test_sents[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdAESvWZPeDu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7c4f9b9a-64a1-4b3d-ad23-cfdce36b449b"
      },
      "cell_type": "code",
      "source": [
        "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-D-L-5VEPeD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "12103a3d-2f2d-47aa-bc38-66c9865aab28"
      },
      "cell_type": "code",
      "source": [
        "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
        "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: O O I-LOC O O O O I-LOC O O O O\n",
            "Correct:   O O I-LOC O O O O I-PER O O O O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lhz0hfk9PeD8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "ZAvn5Op5PeD9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bio_classification_report(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Classification report for a list of BIO-encoded sequences.\n",
        "    It computes token-level metrics and discards \"O\" labels.\n",
        "\n",
        "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
        "    to calculate averages properly!\n",
        "    \"\"\"\n",
        "    lb = LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "\n",
        "    tagset = set(lb.classes_) - {'O'}\n",
        "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "\n",
        "    return classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset,\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahLCmw1GPeEC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Predict entity labels for all sentences in our testing set ('testb' data):"
      ]
    },
    {
      "metadata": {
        "id": "_38pby1WPeED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = [tagger.tag(xseq) for xseq in X_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "24gwDFyEPeEJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "check the result."
      ]
    },
    {
      "metadata": {
        "id": "-InpxuDEPeEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "a049fb72-edf1-458a-8e5c-8662f4c8f228"
      },
      "cell_type": "code",
      "source": [
        "print(bio_classification_report(y_test, y_pred))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "      B-LOC       0.00      0.00      0.00         6\n",
            "      I-LOC       0.83      0.76      0.79      1919\n",
            "     B-MISC       0.00      0.00      0.00         9\n",
            "     I-MISC       0.74      0.73      0.74       909\n",
            "      B-ORG       0.00      0.00      0.00         5\n",
            "      I-ORG       0.73      0.74      0.74      2491\n",
            "      I-PER       0.83      0.88      0.85      2773\n",
            "\n",
            "avg / total       0.79      0.79      0.79      8112\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "m--A9KsKPeEU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's check what classifier learned"
      ]
    },
    {
      "metadata": {
        "id": "7rkZe9yWPeEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "info = tagger.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UlaLR40kPeEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSq7RRFyPeEl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(info.transitions).most_common(15))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwHUGY5PPeEs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(info.transitions).most_common()[-15:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0nw0MaePeE3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check the state features:"
      ]
    },
    {
      "metadata": {
        "id": "ezch1xMOPeE5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-6s %s\" % (weight, label, attr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gH-9PJ7_PeE-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(info.state_features).most_common(20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GoMQ4la_PeFJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(info.state_features).most_common()[-20:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5hEJjGZPeFS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}